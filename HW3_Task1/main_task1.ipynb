{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"main_task1.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"sCXRy7hMe_eN","colab_type":"text"},"source":["## 1. Read Me \n","**Run first cell :** install dependencies \n","\n","**Run second cell :** install files and local environment on the VM, choose which task you want to run by setting task_1 or task_2 value to true\n","\n","**Run third cell :** try diferent init of the agent. When one is found -> the agent is trained  "]},{"cell_type":"code","metadata":{"id":"8Rbvg4vCI9nE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":352},"outputId":"d541608b-1675-4ee6-ef4f-9d1f2b6cea5d","executionInfo":{"status":"ok","timestamp":1587103882631,"user_tz":-480,"elapsed":10280,"user":{"displayName":"N","photoUrl":"","userId":"08619141603155082384"}}},"source":["# Dependencies\n","\n","!pip install torch numpy git+https://github.com/cs4246/gym-grid-driving.git\n","!pip install -U -q PyDrive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/cs4246/gym-grid-driving.git\n","  Cloning https://github.com/cs4246/gym-grid-driving.git to /tmp/pip-req-build-tq1fbag4\n","  Running command git clone -q https://github.com/cs4246/gym-grid-driving.git /tmp/pip-req-build-tq1fbag4\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n","Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-grid-driving==0.0.1) (0.17.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-grid-driving==0.0.1) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-grid-driving==0.0.1) (1.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym->gym-grid-driving==0.0.1) (1.12.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-grid-driving==0.0.1) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-grid-driving==0.0.1) (0.16.0)\n","Building wheels for collected packages: gym-grid-driving\n","  Building wheel for gym-grid-driving (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym-grid-driving: filename=gym_grid_driving-0.0.1-cp36-none-any.whl size=8623 sha256=92dffa1010283dea4ca83e10edbd246d029c4daac19361add077d1cf29142c97\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ddaw4qnb/wheels/e1/30/f2/157c0938ab9bfe9c10c29c9fcab8392f587c9d141f215b67ca\n","Successfully built gym-grid-driving\n","Installing collected packages: gym-grid-driving\n","Successfully installed gym-grid-driving-0.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cjrdeWB-JA1x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":350},"outputId":"6ac6d7cc-83fe-499b-d5cd-84ce204ea1b7","executionInfo":{"status":"ok","timestamp":1587104836078,"user_tz":-480,"elapsed":4707,"user":{"displayName":"N","photoUrl":"","userId":"08619141603155082384"}}},"source":["# Authentification / Initialization of workspace \n","\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Create repo folders \n","\n","task_1 = True\n","# If False task_2 workplace will be downloaded\n","\n","if task_1:\n","  number_task = 1\n","else:\n","  number_task = 2\n","\n","root = '/content'\n","local_download = os.path.join(root,'HW3_Task{}'.format(number_task))\n","\n","if not(os.path.exists(local_download)): \n","  os.mkdir(local_download)\n","\n","local_download_agent = os.path.join(local_download,'agent')\n","\n","if not(os.path.exists(local_download_agent)): \n","  os.mkdir(local_download_agent)\n","\n","  # Download files \n","\n","\n","def download_list(file_list,path_name):\n","    \n","  error_l = [];\n","    \n","  for f in file_list:\n","    # 3. Create & download by id.\n","  \n","    print('file found : title: %s, id: %s' % (f['title'], f['id']))\n","    try:\n","      #print('title: %s, id: %s' % (f['title'], f['id']))\n","      fname = os.path.join(path_name, f['title'])\n","      \n","      # Download only .py files\n","      if fname[-3:] == \".py\":\n","        print('downloading to {}'.format(fname))\n","        f_ = drive.CreateFile({'id': f['id']})\n","        f_.GetContentFile(fname)\n","      \n","    except:\n","      print(\"there is an error\")          \n","      error_l.append(fname)\n","\n","\n","if task_1:\n","  # Initial folder\n","  local_download_path = local_download_agent\n","\n","  # Agent files \n","  file_list = drive.ListFile(\n","        {'q': \"'1ktZR8KIIWEi8Cre92SFomSEchWleHtSu' in parents\"}).GetList()\n","\n","  download_list(file_list,local_download_path)\n","\n","\n","  # Initial files\n","  local_download_path = local_download\n","\n","  file_list = drive.ListFile(\n","        {'q': \"'1x4sJIKHA6NZ5y78AnOJeCZP8abI4gLLO' in parents\"}).GetList()\n","\n","  download_list(file_list,local_download_path)\n","\n","else:\n","\n","  # Initial folder\n","  local_download_path = local_download_agent\n","\n","  # Agent files \n","  file_list = drive.ListFile(\n","        {'q': \"'1PUrHkG6ki4JsiXtKOtvc2vAuR6IJMnCa' in parents\"}).GetList()\n","\n","  download_list(file_list,local_download_path)\n","\n","\n","  # Initial files\n","  local_download_path = local_download\n","\n","  file_list = drive.ListFile(\n","        {'q': \"'17wsroYnRmoTt-OIzDJRrUNvVFmohBVFR' in parents\"}).GetList()\n","\n","  download_list(file_list,local_download_path)\n","\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["file found : title: model.pt, id: 17dLzObCZHQNRtjORHJY1BMrlc6JSIVU8\n","file found : title: dqn.py, id: 1ULRMI4uZ4jtzPqlssTo-C5Ws0VY9AUyz\n","downloading to /content/HW3_Task1/agent/dqn.py\n","file found : title: .ipynb_checkpoints, id: 1q1OUOK4dKijNOml5Q4dFZM2QamGzshDx\n","file found : title: __init__.py, id: 180PYh6Ust-jxJyCnacq6-uhldTP63J8g\n","downloading to /content/HW3_Task1/agent/__init__.py\n","file found : title: main_task1.ipynb, id: 1NCg1-0-mqqEphw_k4TRqwbbzaYlhmlhP\n","file found : title: Task1_A0212190W.zip, id: 1Z1ArkmHt-J_qd26yurcBcc_jB5jEwF-t\n","file found : title: Task1_A0212190W_2, id: 1yp2PvtV548bUrlJUKeui3mtRzYDOxC4z\n","file found : title: Task1_A0212190W_2.zip, id: 1SCUaJprXsvpvmq9zENWIzp4YV8_3OZpP\n","file found : title: Task1_A0212190W 2, id: 1hGKMYS__WaEHxPTReIJUbetLdWdu-B39\n","file found : title: Task1_A0212190W, id: 1Uy6lX_ADufhmZPNQKYdiJIn1fAqeDz5X\n","file found : title: agent, id: 1ktZR8KIIWEi8Cre92SFomSEchWleHtSu\n","file found : title: .ipynb_checkpoints, id: 1ndbYvM_MridcXXHihMy3LYXWuEOEGPR4\n","file found : title: setup.py, id: 1_bWAU4aUo63gpVQNeo0K6MnvzKV88E0j\n","downloading to /content/HW3_Task1/setup.py\n","file found : title: test.py, id: 12TmqKKpFY0iKdA1Z1YLYotleH4KcfeAO\n","downloading to /content/HW3_Task1/test.py\n","file found : title: MANIFEST.in, id: 1jTQ03HR-azZKb5RN7um2BOYyBqHNFFjT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kM9mre8d4VL-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"15a67eae-1bb4-4bb2-9b44-293d95826d8d"},"source":["# TASK 2\n","\n","import time\n","duree = 0 \n","nb_bad_init = 0 \n","# Try for 10 diferent inits\n","\n","for i in range(0,100):\n","  debut = time.time()\n","  # Try an init \n","  !python3 HW3_Task2/agent/models.py --train\n","  duree = (time.time()-debut)\n","  # If good init exit loop\n","  if duree > 500:\n","    break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["AtariDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(4, 4), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (5): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=5376, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=5, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 10]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 87,\tepsilon : 98.6%\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 218,\tepsilon : 97.2%\n","[Episode 30]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 309,\tepsilon : 95.8%\n","[Episode 40]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 424,\tepsilon : 94.5%\n","[Episode 50]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 548,\tepsilon : 93.2%\n","[Episode 60]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 658,\tepsilon : 91.9%\n","[Episode 70]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 773,\tepsilon : 90.6%\n","[Episode 80]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 912,\tepsilon : 89.3%\n","[Episode 90]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1010,\tepsilon : 88.1%\n","[Episode 100]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1112,\tepsilon : 86.8%\n","[Episode 110]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1284,\tepsilon : 85.6%\n","[Episode 120]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1396,\tepsilon : 84.4%\n","[Episode 130]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1481,\tepsilon : 83.2%\n","[Episode 140]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1575,\tepsilon : 82.1%\n","[Episode 150]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1727,\tepsilon : 80.9%\n","[Episode 160]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1830,\tepsilon : 79.8%\n","[Episode 170]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1972,\tepsilon : 78.7%\n","[Episode 180]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2079,\tepsilon : 77.6%\n","[Episode 190]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2174,\tepsilon : 76.5%\n","[Episode 200]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2304,\tepsilon : 75.4%\n","[Episode 210]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2454,\tepsilon : 74.3%\n","[Episode 220]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2586,\tepsilon : 73.3%\n","[Episode 230]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2717,\tepsilon : 72.3%\n","[Episode 240]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2869,\tepsilon : 71.3%\n","[Episode 250]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2967,\tepsilon : 70.3%\n","[Episode 260]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3154,\tepsilon : 69.3%\n","[Episode 270]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3274,\tepsilon : 68.3%\n","[Episode 280]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3481,\tepsilon : 67.4%\n","[Episode 290]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3621,\tepsilon : 66.4%\n","[Episode 300]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3768,\tepsilon : 65.5%\n","[Episode 310]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3936,\tepsilon : 64.6%\n","Bad initialization. Please restart the training.\n","AtariDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(4, 4), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (5): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=5376, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=5, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 10]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 131,\tepsilon : 98.6%\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 226,\tepsilon : 97.2%\n","[Episode 30]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 372,\tepsilon : 95.8%\n","[Episode 40]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 489,\tepsilon : 94.5%\n","[Episode 50]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 588,\tepsilon : 93.2%\n","[Episode 60]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 699,\tepsilon : 91.9%\n","[Episode 70]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 826,\tepsilon : 90.6%\n","[Episode 80]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 931,\tepsilon : 89.3%\n","[Episode 90]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1103,\tepsilon : 88.1%\n","[Episode 100]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1220,\tepsilon : 86.8%\n","[Episode 110]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1304,\tepsilon : 85.6%\n","[Episode 120]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1383,\tepsilon : 84.4%\n","[Episode 130]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1505,\tepsilon : 83.2%\n","[Episode 140]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1646,\tepsilon : 82.1%\n","[Episode 150]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1763,\tepsilon : 80.9%\n","[Episode 160]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1876,\tepsilon : 79.8%\n","[Episode 170]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2022,\tepsilon : 78.7%\n","[Episode 180]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2100,\tepsilon : 77.6%\n","[Episode 190]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2203,\tepsilon : 76.5%\n","[Episode 200]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2285,\tepsilon : 75.4%\n","[Episode 210]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2394,\tepsilon : 74.3%\n","[Episode 220]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2513,\tepsilon : 73.3%\n","[Episode 230]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2598,\tepsilon : 72.3%\n","[Episode 240]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2713,\tepsilon : 71.3%\n","[Episode 250]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2818,\tepsilon : 70.3%\n","[Episode 260]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2962,\tepsilon : 69.3%\n","[Episode 270]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3097,\tepsilon : 68.3%\n","[Episode 280]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3247,\tepsilon : 67.4%\n","[Episode 290]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3471,\tepsilon : 66.4%\n","[Episode 300]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3678,\tepsilon : 65.5%\n","[Episode 310]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 3825,\tepsilon : 64.6%\n","Bad initialization. Please restart the training.\n","AtariDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(4, 4), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (5): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=5376, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=5, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 10]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 161,\tepsilon : 98.6%\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 247,\tepsilon : 97.2%\n","[Episode 30]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 354,\tepsilon : 95.8%\n","[Episode 40]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 512,\tepsilon : 94.5%\n","[Episode 50]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 622,\tepsilon : 93.2%\n","[Episode 60]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 761,\tepsilon : 91.9%\n","[Episode 70]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 901,\tepsilon : 90.6%\n","[Episode 80]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1050,\tepsilon : 89.3%\n","[Episode 90]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1154,\tepsilon : 88.1%\n","[Episode 100]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1310,\tepsilon : 86.8%\n","[Episode 110]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1361,\tepsilon : 85.6%\n","[Episode 120]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1480,\tepsilon : 84.4%\n","[Episode 130]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1581,\tepsilon : 83.2%\n","[Episode 140]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1702,\tepsilon : 82.1%\n","[Episode 150]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1817,\tepsilon : 80.9%\n","[Episode 160]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 1941,\tepsilon : 79.8%\n","[Episode 170]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2053,\tepsilon : 78.7%\n","[Episode 180]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2123,\tepsilon : 77.6%\n","[Episode 190]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2249,\tepsilon : 76.5%\n","[Episode 200]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2383,\tepsilon : 75.4%\n","[Episode 210]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2497,\tepsilon : 74.3%\n","[Episode 220]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 2625,\tepsilon : 73.3%\n","[Episode 230]\tavg rewards : 0.045,\tavg loss: : nan,\tbuffer size : 2757,\tepsilon : 72.3%\n","[Episode 240]\tavg rewards : 0.043,\tavg loss: : nan,\tbuffer size : 2919,\tepsilon : 71.3%\n","[Episode 250]\tavg rewards : 0.041,\tavg loss: : nan,\tbuffer size : 3012,\tepsilon : 70.3%\n","[Episode 260]\tavg rewards : 0.040,\tavg loss: : nan,\tbuffer size : 3154,\tepsilon : 69.3%\n","[Episode 270]\tavg rewards : 0.038,\tavg loss: : nan,\tbuffer size : 3278,\tepsilon : 68.3%\n","[Episode 280]\tavg rewards : 0.037,\tavg loss: : nan,\tbuffer size : 3395,\tepsilon : 67.4%\n","[Episode 290]\tavg rewards : 0.036,\tavg loss: : nan,\tbuffer size : 3477,\tepsilon : 66.4%\n","[Episode 300]\tavg rewards : 0.034,\tavg loss: : nan,\tbuffer size : 3611,\tepsilon : 65.5%\n","[Episode 310]\tavg rewards : 0.033,\tavg loss: : nan,\tbuffer size : 3788,\tepsilon : 64.6%\n","[Episode 320]\tavg rewards : 0.032,\tavg loss: : nan,\tbuffer size : 3900,\tepsilon : 63.7%\n","Bad initialization. Please restart the training.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oEhO5nj6eZz8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"4adc4865-e2bd-4ea9-dd3b-813b7883cd23","executionInfo":{"status":"ok","timestamp":1587116863487,"user_tz":-480,"elapsed":341065,"user":{"displayName":"N","photoUrl":"","userId":"08619141603155082384"}}},"source":["# Test for TASK 2:\n","!python3 HW3_Task2/agent/__init__.py\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[task_2_tmax50] 300 run(s) avg rewards : 6.6\n","[task_2_tmax40] 300 run(s) avg rewards : 1.0\n","Point: 3.8333333333333335\n","Local runtime: 337.30871415138245 seconds --- safe\n","WARNING: do note that this might not reflect the runtime on the server.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1RIkGEjdJw83","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"05c44578-08f2-4f27-bbfa-e4e2924d0f62","executionInfo":{"status":"error","timestamp":1587106672667,"user_tz":-480,"elapsed":162685,"user":{"displayName":"N","photoUrl":"","userId":"08619141603155082384"}}},"source":["# TASK 1\n","\n","import time\n","duree = 0 \n","nb_bad_init = 0 \n","# Try for 10 diferent inits\n","\n","for i in range(0,10):\n","  debut = time.time()\n","  # Try an init \n","  !python3 HW3_Task1/agent/dqn.py --train\n","  duree = (time.time()-debut)\n","  # If good init exit loop\n","  if duree > 100:\n","    break"],"execution_count":14,"outputs":[{"output_type":"stream","text":["ConvDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(2, 2), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n","    (3): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=1024, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=256, out_features=4, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 112,\tepsilon : 96.1%\n","[Episode 40]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 204,\tepsilon : 92.4%\n","[Episode 60]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 313,\tepsilon : 88.8%\n","[Episode 80]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 415,\tepsilon : 85.4%\n","[Episode 100]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 505,\tepsilon : 82.1%\n","[Episode 120]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 601,\tepsilon : 78.9%\n","[Episode 140]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 686,\tepsilon : 75.8%\n","[Episode 160]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 766,\tepsilon : 72.9%\n","[Episode 180]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 836,\tepsilon : 70.1%\n","[Episode 200]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 909,\tepsilon : 67.4%\n","[Episode 220]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 997,\tepsilon : 64.8%\n","Bad initialization. Please restart the training.\n","ConvDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(2, 2), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n","    (3): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=1024, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=256, out_features=4, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 107,\tepsilon : 96.1%\n","[Episode 40]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 198,\tepsilon : 92.4%\n","[Episode 60]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 309,\tepsilon : 88.8%\n","[Episode 80]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 431,\tepsilon : 85.4%\n","[Episode 100]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 553,\tepsilon : 82.1%\n","[Episode 120]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 678,\tepsilon : 78.9%\n","[Episode 140]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 795,\tepsilon : 75.8%\n","[Episode 160]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 918,\tepsilon : 72.9%\n","Bad initialization. Please restart the training.\n","ConvDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(2, 2), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n","    (3): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=1024, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=256, out_features=4, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 85,\tepsilon : 96.1%\n","[Episode 40]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 174,\tepsilon : 92.4%\n","[Episode 60]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 262,\tepsilon : 88.8%\n","[Episode 80]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 368,\tepsilon : 85.4%\n","[Episode 100]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 469,\tepsilon : 82.1%\n","[Episode 120]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 574,\tepsilon : 78.9%\n","[Episode 140]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 681,\tepsilon : 75.8%\n","[Episode 160]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 775,\tepsilon : 72.9%\n","[Episode 180]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 891,\tepsilon : 70.1%\n","Bad initialization. Please restart the training.\n","ConvDQN(\n","  (features): Sequential(\n","    (0): Conv2d(4, 32, kernel_size=(2, 2), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n","    (3): ReLU()\n","  )\n","  (layers): Sequential(\n","    (0): Linear(in_features=1024, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=256, out_features=4, bias=True)\n","  )\n",")\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","[Episode 20]\tavg rewards : 0.000,\tavg loss: : nan,\tbuffer size : 117,\tepsilon : 96.1%\n","[Episode 40]\tavg rewards : 0.476,\tavg loss: : nan,\tbuffer size : 216,\tepsilon : 92.4%\n","[Episode 60]\tavg rewards : 0.244,\tavg loss: : nan,\tbuffer size : 294,\tepsilon : 88.8%\n","[Episode 80]\tavg rewards : 0.164,\tavg loss: : nan,\tbuffer size : 377,\tepsilon : 85.4%\n","[Episode 100]\tavg rewards : 0.123,\tavg loss: : nan,\tbuffer size : 471,\tepsilon : 82.1%\n","[Episode 120]\tavg rewards : 0.198,\tavg loss: : nan,\tbuffer size : 565,\tepsilon : 78.9%\n","[Episode 140]\tavg rewards : 0.165,\tavg loss: : nan,\tbuffer size : 656,\tepsilon : 75.8%\n","[Episode 160]\tavg rewards : 0.213,\tavg loss: : nan,\tbuffer size : 732,\tepsilon : 72.9%\n","[Episode 180]\tavg rewards : 0.186,\tavg loss: : nan,\tbuffer size : 805,\tepsilon : 70.1%\n","[Episode 200]\tavg rewards : 0.276,\tavg loss: : nan,\tbuffer size : 887,\tepsilon : 67.4%\n","[Episode 220]\tavg rewards : 0.249,\tavg loss: : nan,\tbuffer size : 970,\tepsilon : 64.8%\n","[Episode 240]\tavg rewards : 0.271,\tavg loss: : nan,\tbuffer size : 1038,\tepsilon : 62.3%\n","[Episode 260]\tavg rewards : 0.249,\tavg loss: : 0.146596,\tbuffer size : 1138,\tepsilon : 59.9%\n","[Episode 280]\tavg rewards : 0.268,\tavg loss: : 0.280962,\tbuffer size : 1257,\tepsilon : 57.5%\n","[Episode 300]\tavg rewards : 0.285,\tavg loss: : 0.308784,\tbuffer size : 1384,\tepsilon : 55.3%\n","[Episode 320]\tavg rewards : 0.266,\tavg loss: : 0.339886,\tbuffer size : 1491,\tepsilon : 53.2%\n","[Episode 340]\tavg rewards : 0.249,\tavg loss: : 0.376759,\tbuffer size : 1616,\tepsilon : 51.2%\n","[Episode 360]\tavg rewards : 0.293,\tavg loss: : 0.413299,\tbuffer size : 1730,\tepsilon : 49.2%\n","[Episode 380]\tavg rewards : 0.277,\tavg loss: : 0.466195,\tbuffer size : 1833,\tepsilon : 47.3%\n","[Episode 400]\tavg rewards : 0.315,\tavg loss: : 0.518123,\tbuffer size : 1953,\tepsilon : 45.5%\n","[Episode 420]\tavg rewards : 0.349,\tavg loss: : 0.581988,\tbuffer size : 2059,\tepsilon : 43.7%\n","[Episode 440]\tavg rewards : 0.451,\tavg loss: : 0.629115,\tbuffer size : 2197,\tepsilon : 42.1%\n","[Episode 460]\tavg rewards : 0.476,\tavg loss: : 0.657869,\tbuffer size : 2323,\tepsilon : 40.5%\n","[Episode 480]\tavg rewards : 0.456,\tavg loss: : 0.681878,\tbuffer size : 2463,\tepsilon : 38.9%\n","[Episode 500]\tavg rewards : 0.561,\tavg loss: : 0.684872,\tbuffer size : 2605,\tepsilon : 37.4%\n","[Episode 520]\tavg rewards : 0.559,\tavg loss: : 0.680807,\tbuffer size : 2737,\tepsilon : 36.0%\n","[Episode 540]\tavg rewards : 0.537,\tavg loss: : 0.684816,\tbuffer size : 2875,\tepsilon : 34.6%\n","[Episode 560]\tavg rewards : 0.573,\tavg loss: : 0.686589,\tbuffer size : 3013,\tepsilon : 33.3%\n","[Episode 580]\tavg rewards : 0.606,\tavg loss: : 0.679884,\tbuffer size : 3150,\tepsilon : 32.0%\n","[Episode 600]\tavg rewards : 0.688,\tavg loss: : 0.675158,\tbuffer size : 3291,\tepsilon : 30.8%\n","[Episode 620]\tavg rewards : 0.699,\tavg loss: : 0.666817,\tbuffer size : 3408,\tepsilon : 29.6%\n","[Episode 640]\tavg rewards : 0.757,\tavg loss: : 0.660289,\tbuffer size : 3552,\tepsilon : 28.5%\n","[Episode 660]\tavg rewards : 0.842,\tavg loss: : 0.658984,\tbuffer size : 3698,\tepsilon : 27.4%\n","[Episode 680]\tavg rewards : 0.877,\tavg loss: : 0.658664,\tbuffer size : 3833,\tepsilon : 26.4%\n","[Episode 700]\tavg rewards : 0.910,\tavg loss: : 0.665330,\tbuffer size : 3966,\tepsilon : 25.4%\n","[Episode 720]\tavg rewards : 1.013,\tavg loss: : 0.672500,\tbuffer size : 4102,\tepsilon : 24.5%\n","[Episode 740]\tavg rewards : 1.068,\tavg loss: : 0.674238,\tbuffer size : 4233,\tepsilon : 23.5%\n","[Episode 760]\tavg rewards : 1.120,\tavg loss: : 0.672564,\tbuffer size : 4374,\tepsilon : 22.7%\n","[Episode 780]\tavg rewards : 1.222,\tavg loss: : 0.673255,\tbuffer size : 4502,\tepsilon : 21.8%\n","[Episode 800]\tavg rewards : 1.293,\tavg loss: : 0.675336,\tbuffer size : 4650,\tepsilon : 21.0%\n","[Episode 820]\tavg rewards : 1.298,\tavg loss: : 0.680509,\tbuffer size : 4782,\tepsilon : 20.2%\n","[Episode 840]\tavg rewards : 1.401,\tavg loss: : 0.687351,\tbuffer size : 4949,\tepsilon : 19.5%\n","[Episode 860]\tavg rewards : 1.463,\tavg loss: : 0.691345,\tbuffer size : 5000,\tepsilon : 18.7%\n","[Episode 880]\tavg rewards : 1.556,\tavg loss: : 0.693100,\tbuffer size : 5000,\tepsilon : 18.0%\n","[Episode 900]\tavg rewards : 1.578,\tavg loss: : 0.694293,\tbuffer size : 5000,\tepsilon : 17.4%\n","[Episode 920]\tavg rewards : 1.665,\tavg loss: : 0.694739,\tbuffer size : 5000,\tepsilon : 16.7%\n","[Episode 940]\tavg rewards : 1.726,\tavg loss: : 0.694911,\tbuffer size : 5000,\tepsilon : 16.1%\n","[Episode 960]\tavg rewards : 1.775,\tavg loss: : 0.695281,\tbuffer size : 5000,\tepsilon : 15.5%\n","[Episode 980]\tavg rewards : 1.863,\tavg loss: : 0.694479,\tbuffer size : 5000,\tepsilon : 14.9%\n","Traceback (most recent call last):\n","  File \"HW3_Task1/agent/dqn.py\", line 392, in <module>\n","    model = train(ConvDQN, env)\n","  File \"HW3_Task1/agent/dqn.py\", line 319, in train\n","    loss = optimize(model, target, memory, optimizer)\n","  File \"HW3_Task1/agent/dqn.py\", line 249, in optimize\n","    batch = memory.sample(batch_size)\n","  File \"HW3_Task1/agent/dqn.py\", line 103, in sample\n","    states_batch, actions_batch, rewards_batch, dones_batch, next_states_batch = list(map(torch.tensor, list(zip(*batch))))\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-c525fe8926e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mdebut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Try an init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 HW3_Task1/agent/dqn.py --train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mduree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdebut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# If good init exit loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ru96YQP2MC35","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}